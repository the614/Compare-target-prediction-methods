#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlalchemy
import pandas as pd

# Connect to the PostgreSQL database using SQLAlchemy
engine = sqlalchemy.create_engine('postgresql://postgres:000000@localhost:5432/chembl_34') # Use your own postgres password and localhost

# Define the query to retrieve data
query = """
SELECT
    compound_records.compound_key AS compound_id,
    molecule_dictionary.chembl_id AS molecule_chembl_id,
    molecule_dictionary.molregno,
    activities.standard_value,
    activities.standard_units,
    activities.standard_type,
    target_dictionary.chembl_id AS target_chembl_id,
    target_dictionary.pref_name AS target_name
FROM
    activities
JOIN
    assays ON activities.assay_id = assays.assay_id
JOIN
    target_dictionary ON assays.tid = target_dictionary.tid
JOIN
    compound_records ON activities.record_id = compound_records.record_id
JOIN
    molecule_dictionary ON compound_records.molregno = molecule_dictionary.molregno
WHERE
    activities.standard_value <= 10000 AND
    activities.standard_units = 'nM' AND
    (activities.standard_type = 'IC50' OR
     activities.standard_type = 'Ki' OR
     activities.standard_type = 'EC50')
"""

# Execute the query and load the results into a Pandas DataFrame
df = pd.read_sql_query(query, engine)

# Data cleaning
# Exclude data on multi-protein complexes and non-specific experiments
df = df[~df['target_name'].str.contains('multiple|complex', case=False, na=False)]

# Remove duplicate entries
df = df.drop_duplicates(subset=['compound_id', 'target_chembl_id'])

# Export the cleaned data to a CSV file
df.to_csv('Chembl_34_filter.csv', index=False)

# Print confirmation of file export
print("Filtered data exported to CSV file.")
